import os

import fitz
import numpy as np
from dotenv import load_dotenv, __main__
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from openai import OpenAI
from sympy import false

load_dotenv()

api_key = os.getenv("ZHIPU_API_KEY")
zhipu_url = os.getenv("ZHIPU_URL")

# client = OpenAILike(
#         model="glm-4.7",  # æˆ– "glm-4-plus"ã€"glm-4.7" ç­‰ï¼ˆè§†æ‚¨çš„è´¦å·æ”¯æŒè€Œå®šï¼‰
#         api_key=api_key,
#         api_base=zhipu_url,
#         is_chat_model=True
#     )
client = OpenAI(
    base_url="https://open.bigmodel.cn/api/paas/v4/",  # æ™ºè°±å®˜æ–¹ OpenAI å…¼å®¹åœ°å€
    api_key=os.getenv("ZHIPU_API_KEY")  # å¿…é¡»æ˜¾å¼ä¼ å…¥ï¼Œä¸èƒ½çœç•¥
)

def extra_text_from_pdf(pdf_path):
    """ ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬ """
    mypdf = fitz.open(pdf_path)
    all_text = ""
    for page_num in range(mypdf.page_count):
        my_page = mypdf[page_num]
        text = my_page.get_text("text")
        all_text += text

    return all_text

def analyze_document_characteristics(text):
    """
    åˆ†ææ–‡æ¡£ç‰¹å¾ä»¥ç¡®å®šæœ€ä¼˜åˆ†å—å¤§å°

    Args:
        text (str): æ–‡æ¡£æ–‡æœ¬

    Returns:
        dict: æ–‡æ¡£ç‰¹å¾åˆ†æç»“æœ
    """
    # åŸºç¡€ç»Ÿè®¡
    total_length = len(text)
    sentences = text.split(".")
    paragraphs = text.split("\n\n")

    # è®¡ç®—ç‰¹å¾
    avg_sentence_length = np.mean([len(s.strip()) for s in sentences if s.strip()])
    avg_paragraph_length = np.mean([len(p.strip()) for p in paragraphs if p.strip()])

    # ä¿¡æ¯å¯†åº¦åˆ†æ
    unique_words = len(set(text.lower().split()))
    total_words = len(text.split())
    vocabulary_richness = unique_words / total_words if total_words > 0 else 0

    # ç»“æ„å¤æ‚åº¦
    line_breaks = text.count('\n')
    structural_complexity = line_breaks / total_length if total_length > 0 else 0

    characteristics = {
        'total_length': total_length,
        'avg_sentence_length': avg_sentence_length,
        'avg_paragraph_length': avg_paragraph_length,
        'vocabulary_richness': vocabulary_richness,
        'structural_complexity': structural_complexity,
        'sentence_count': len([s for s in sentences if s.strip()]),
        'paragraph_count': len([p for p in paragraphs if p.strip()])
    }

    return characteristics

def analyze_query_characteristics(query):
    """
    åˆ†ææŸ¥è¯¢ç‰¹å¾

    Args:
        query (str): ç”¨æˆ·æŸ¥è¯¢

    Returns:
        dict: æŸ¥è¯¢ç‰¹å¾åˆ†æç»“æœ
    """
    query_length = len(query)
    word_count = len(query.split())
    question_words = ['what', 'how', 'why', 'when', 'where', 'who', 'which']
    # has_question_word = any(word.lower() in query.lower()  for word in question_words)
    has_question_word = False
    for word in question_words:
        if word in query.lower():
            has_question_word = True

    # æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°
    complexity_indicators = ['and', 'or', 'compare', 'difference', 'relationship', 'impact']
    # complexity_score = sum(1 for indicator in complexity_indicators if indicator in query.lower())
    complexity_score = 0
    for indicator in complexity_indicators:
        if indicator in query.lower():
            complexity_score += 1

    return {
        'query_length': query_length,
        'word_count': word_count,
        'has_question_word': has_question_word,
        'complexity_indicators': complexity_indicators,
        'complexity_score': complexity_score,
        'is_specific': word_count < 5,
        'is_complex': complexity_score >= 2
    }

def recommend_chunk_size(doc_characteristics, query_characteristics):
    """
    åŸºäºæ–‡æ¡£å’ŒæŸ¥è¯¢ç‰¹å¾æ¨èæœ€ä¼˜åˆ†å—å¤§å°

    Args:
        doc_characteristics (dict): æ–‡æ¡£ç‰¹å¾
        query_characteristics (dict): æŸ¥è¯¢ç‰¹å¾

    Returns:
        tuple: (æ¨èçš„åˆ†å—å¤§å°, é‡å å¤§å°, æ¨èç†ç”±)
    """
    base_chunk_size = 1000

    # æ ¹æ®æ–‡æ¡£ç‰¹å¾è°ƒæ•´
    if doc_characteristics['avg_paragraph_length'] > 500:
        # æ®µè½è¾ƒé•¿çš„æ–‡æ¡£ï¼Œä½¿ç”¨è¾ƒå¤§çš„åˆ†å—
        doc_adjustment = 1.3
        reason = "æ–‡æ¡£æ®µè½è¾ƒé•¿ï¼Œ"
    elif doc_characteristics['avg_paragraph_length'] < 200:
        # æ®µè½è¾ƒçŸ­çš„æ–‡æ¡£ï¼Œä½¿ç”¨è¾ƒå°çš„åˆ†å—
        doc_adjustment = 0.7
        reason = "æ–‡æ¡£æ®µè½è¾ƒçŸ­ï¼Œ"
    else:
        doc_adjustment = 1.0
        reason = "æ–‡æ¡£ç»“æ„é€‚ä¸­ï¼Œ"

    # æ ¹æ®è¯æ±‡ä¸°å¯Œåº¦è°ƒæ•´
    if doc_characteristics['vocabulary_richness'] > 0.7:
        vocab_adjustment = 1.2  # è¯æ±‡ä¸°å¯Œï¼Œéœ€è¦æ›´å¤§çš„ä¸Šä¸‹æ–‡
        reason += "è¯æ±‡ä¸°å¯Œï¼Œ"
    elif doc_characteristics['vocabulary_richness'] < 0.4:
        vocab_adjustment = 0.8  # è¯æ±‡å•ä¸€ï¼Œå¯ä»¥ä½¿ç”¨è¾ƒå°åˆ†å—
        reason += "è¯æ±‡ç›¸å¯¹å•ä¸€ï¼Œ"
    else:
        vocab_adjustment = 1.0
        reason += "è¯æ±‡å¯†åº¦é€‚ä¸­ï¼Œ"

    # æ ¹æ®æŸ¥è¯¢ç‰¹å¾è°ƒæ•´
    if query_characteristics['is_complex']:
        query_adjustment = 1.4  # å¤æ‚æŸ¥è¯¢éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡
        reason += "æŸ¥è¯¢å¤æ‚éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ï¼Œ"
    elif query_characteristics['is_specific']:
        query_adjustment = 0.8  # å…·ä½“æŸ¥è¯¢å¯ä»¥ä½¿ç”¨è¾ƒå°åˆ†å—
        reason += "æŸ¥è¯¢å…·ä½“å¯ä½¿ç”¨è¾ƒå°åˆ†å—ï¼Œ"
    else:
        query_adjustment = 1.0
        reason += "æŸ¥è¯¢å¤æ‚åº¦é€‚ä¸­ï¼Œ"

    # è®¡ç®—æœ€ç»ˆåˆ†å—å¤§å°
    final_chunk_size = int(base_chunk_size * doc_adjustment * vocab_adjustment * query_adjustment)

    # ç¡®ä¿åˆ†å—å¤§å°åœ¨åˆç†èŒƒå›´å†…
    final_chunk_size = max(400, min(2000, final_chunk_size))

    # è®¡ç®—é‡å å¤§å°ï¼ˆé€šå¸¸ä¸ºåˆ†å—å¤§å°çš„20%ï¼‰
    overlap_size = int(final_chunk_size * 0.2)

    reason += f"æ¨èåˆ†å—å¤§å°ä¸º{final_chunk_size}å­—ç¬¦"

    return final_chunk_size, overlap_size, reason

def create_chunks_with_size(text, chunk_size, overlap_size):
    """
    ä½¿ç”¨æŒ‡å®šå¤§å°åˆ›å»ºæ–‡æœ¬åˆ†å—

    Args:
        text (str): è¦åˆ†å—çš„æ–‡æœ¬
        chunk_size (int): åˆ†å—å¤§å°
        overlap_size (int): é‡å å¤§å°

    Returns:
        List[str]: æ–‡æœ¬åˆ†å—åˆ—è¡¨
    """
    chunks = []

    step = chunk_size - overlap_size

    for i in range(0, len(text), step):
        chunk = text[i:i + step]
        if chunk.strip():
            chunks.append(chunk)

    return chunks

def create_embeddings(text, model="BAAI/bge-base-en-v1.5"):
    """ ä¸ºç»™å®šæ–‡æœ¬åˆ›å»ºå‘é‡ """
    embedding_model = HuggingFaceEmbedding(model_name=model)
    if isinstance(text, list):
        response = embedding_model.get_text_embedding_batch(text)
    else:
        response = embedding_model.get_text_embedding(text)

    return response

def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

def search_with_chunks(query, chunks, embeddings, top_k=5):
    """
    ä½¿ç”¨ç»™å®šçš„åˆ†å—å’ŒåµŒå…¥è¿›è¡Œæœç´¢

    Args:
        query (str): æŸ¥è¯¢
        chunks (List[str]): æ–‡æœ¬åˆ†å—
        embeddings (List): åµŒå…¥å‘é‡
        top_k (int): è¿”å›çš„ç»“æœæ•°é‡

    Returns:
        List[Dict]: æœç´¢ç»“æœ
    """
    similarities = []
    query_embeddings = create_embeddings(query)
    for i,chunk_embedding  in enumerate(embeddings):
        similarity = cosine_similarity(
            np.array(query_embeddings),
            np.array(chunk_embedding)
        )
        similarities.append((i, similarity, chunks[i]))

    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)

    results = []
    for i in range(min(top_k, len(similarities))):
        idx, score, chunk = similarities[i]
        results.append({
            "index": idx,
            "score": score,
            "chunk": chunk,
        })

    return results

def evaluate_chunk_size_performance(query, text, chunk_size, overlap_size):
    """
    è¯„ä¼°ç‰¹å®šåˆ†å—å¤§å°çš„æ€§èƒ½

    Args:
        query (str): æŸ¥è¯¢
        text (str): æ–‡æ¡£æ–‡æœ¬
        chunk_size (int): åˆ†å—å¤§å°
        overlap_size (int): é‡å å¤§å°

    Returns:
        dict: æ€§èƒ½è¯„ä¼°ç»“æœ
    """
    # åˆ›å»ºåˆ†å—
    chunks = create_chunks_with_size(text, chunk_size, overlap_size)

    # åˆ›å»ºåµŒå…¥
    embeddings = create_embeddings(chunks)

    # æ‰§è¡Œæœç´¢
    search_results = search_with_chunks(query, chunks, embeddings, top_k=3)
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    avg_similarity = np.mean([result['score'] for result in search_results])
    chunk_count = len(chunks)
    avg_chunk_length = np.mean([len(chunk) for chunk in chunks])

    # è®¡ç®—ä¸Šä¸‹æ–‡è¦†ç›–ç‡ï¼ˆtopç»“æœçš„æ€»é•¿åº¦ï¼‰
    total_context_length = sum(len(result['chunk']) for result in search_results)

    return {
        'chunk_size': chunk_size,
        'overlap_size': overlap_size,
        'chunk_count': chunk_count,
        'avg_chunk_length': avg_chunk_length,
        'avg_similarity': avg_similarity,
        'total_context_length': total_context_length,
        'search_results': search_results
    }

def compare_chunk_sizes(query, text, chunk_sizes=None):
    """
    æ¯”è¾ƒä¸åŒåˆ†å—å¤§å°çš„æ€§èƒ½

    Args:
        query (str): æŸ¥è¯¢
        text (str): æ–‡æ¡£æ–‡æœ¬
        chunk_sizes (List[int], optional): è¦æ¯”è¾ƒçš„åˆ†å—å¤§å°åˆ—è¡¨

    Returns:
        List[Dict]: å„ç§åˆ†å—å¤§å°çš„æ€§èƒ½æ¯”è¾ƒç»“æœ
    """
    if chunk_sizes is None:
        chunk_sizes = [400, 600, 800, 1000, 1200, 1500]

    results = []

    print(f"æ¯”è¾ƒä¸åŒåˆ†å—å¤§å°çš„æ€§èƒ½...")

    for chunk_size in chunk_sizes:
        overlap_size = int(chunk_size * 0.2)  # 20%é‡å 

        performance = evaluate_chunk_size_performance(
            query, text, chunk_size, overlap_size
        )

        results.append(performance)

        print(f"åˆ†å—å¤§å° {chunk_size}: å¹³å‡ç›¸ä¼¼åº¦ {performance['avg_similarity']:.4f}, "
              f"åˆ†å—æ•°é‡ {performance['chunk_count']}")

    # æŒ‰å¹³å‡ç›¸ä¼¼åº¦æ’åº
    results.sort(key=lambda x: x['avg_similarity'], reverse=True)

    return results

def generate_response(query, context, model="glm-4.7"):
    """ åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­” """
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œä¸¥æ ¼åŸºäºç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœæ— æ³•ä»æä¾›çš„ä¸Šä¸‹æ–‡ä¸­å¾—å‡ºç­”æ¡ˆï¼Œè¯·å›ç­”ï¼š'æˆ‘æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚'"

    user_prompt = f"""
    ä¸Šä¸‹æ–‡ï¼š
    {context}
    
    é—®é¢˜ï¼š{query}
    
    è¯·åŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚
    """

    response = client.chat.completions.create(
        model=model,
        temperature=0,
        messages=[
            {"role":"system", "content":system_prompt},
            {"role":"user", "content":user_prompt},
        ]
    )

    return response.choices[0].message.content

def adaptive_chunking_rag(pad_path, query):
    """
    ä½¿ç”¨è‡ªé€‚åº”åˆ†å—çš„å®Œæ•´RAGæµç¨‹

    Args:
        pdf_path (str): PDFæ–‡æ¡£è·¯å¾„
        query (str): ç”¨æˆ·æŸ¥è¯¢

    Returns:
        dict: å®Œæ•´çš„å¤„ç†ç»“æœ
    """
    print("å¼€å§‹è‡ªé€‚åº”åˆ†å—RAGæµç¨‹...")

    # 1. æå–æ–‡æ¡£æ–‡æœ¬
    print("1. æå–æ–‡æ¡£æ–‡æœ¬...")
    text = extra_text_from_pdf(pad_path)
    print(f"æ–‡æ¡£æ€»é•¿åº¦{len(text)}å­—ç¬¦")

    # 2. åˆ†ææ–‡æ¡£ç‰¹å¾
    print("2. åˆ†ææ–‡æ¡£ç‰¹å¾...")
    doc_characteristics = analyze_document_characteristics(text)
    print(f"æ–‡æ¡£ç‰¹å¾: å¹³å‡æ®µè½é•¿åº¦={doc_characteristics['avg_paragraph_length']:.1f}, "
          f"è¯æ±‡ä¸°å¯Œåº¦={doc_characteristics['vocabulary_richness']:.3f}")

    # 3. åˆ†ææŸ¥è¯¢ç‰¹å¾
    print("3. åˆ†ææŸ¥è¯¢ç‰¹å¾...")
    query_characteristics = analyze_query_characteristics(query)
    print(f"æŸ¥è¯¢ç‰¹å¾: é•¿åº¦={query_characteristics['query_length']}, "
          f"å¤æ‚åº¦={query_characteristics['complexity_score']}")

    #4. æ¨èæœ€ä¼˜åˆ†å—å¤§å°
    print("4. æ¨èæœ€ä¼˜åˆ†å—å¤§å°...")
    recommended_chunk_size, recommended_overlap, reason = recommend_chunk_size(
        doc_characteristics, query_characteristics
    )
    print(f"æ¨èç­–ç•¥: {reason}")

    # 5. æ¯”è¾ƒä¸åŒåˆ†å—å¤§å°çš„æ€§èƒ½
    print("5. æ¯”è¾ƒä¸åŒåˆ†å—å¤§å°çš„æ€§èƒ½...")
    comparison_results = compare_chunk_sizes(
        query, text,
        chunk_sizes=[400, 600, 800, recommended_chunk_size, 1200, 1500]
    )

    # 6. ä½¿ç”¨æœ€ä½³åˆ†å—å¤§å°è¿›è¡ŒRAG
    print("6. ä½¿ç”¨æœ€ä½³åˆ†å—å¤§å°è¿›è¡ŒRAG...")
    best_performance = comparison_results[0]
    best_chunk_size = best_performance['chunk_size']

    print(f"é€‰æ‹©æœ€ä½³åˆ†å—å¤§å°: {best_chunk_size}")

    # 7. ç”Ÿæˆæœ€ç»ˆå›ç­”
    context = "\n\n".join([
        f"æ®µè½{i + 1}: {result['chunk']}"
        for i, result in enumerate(best_performance['search_results'])
    ])

    response = generate_response(query, context)

    return {
        'query': query,
        'doc_characteristics': doc_characteristics,
        'query_characteristics': query_characteristics,
        'recommended_chunk_size': recommended_chunk_size,
        'recommended_reason': reason,
        'comparison_results': comparison_results,
        'best_chunk_size': best_chunk_size,
        'best_performance': best_performance,
        'context': context,
        'response': response
    }

if __name__ == "__main__":
    # è‡ªé€‚åº”åˆ†å—RAGå®Œæ•´æ¼”ç¤º
    pdf_path = "../data/AI_Information.pdf"
    query = "æ·±åº¦å­¦ä¹ çš„ä¸»è¦åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ"

    print(f"æŸ¥è¯¢: {query}")
    print("=" * 60)

    # æ‰§è¡Œè‡ªé€‚åº”åˆ†å—RAG
    result = adaptive_chunking_rag(pdf_path, query)

    # æ˜¾ç¤ºæ–‡æ¡£åˆ†æç»“æœ
    print(f"\nğŸ“Š æ–‡æ¡£ç‰¹å¾åˆ†æ:")
    doc_chars = result['doc_characteristics']
    print(f"- æ€»é•¿åº¦: {doc_chars['total_length']} å­—ç¬¦")
    print(f"- å¹³å‡å¥å­é•¿åº¦: {doc_chars['avg_sentence_length']:.1f} å­—ç¬¦")
    print(f"- å¹³å‡æ®µè½é•¿åº¦: {doc_chars['avg_paragraph_length']:.1f} å­—ç¬¦")
    print(f"- è¯æ±‡ä¸°å¯Œåº¦: {doc_chars['vocabulary_richness']:.3f}")

    # æ˜¾ç¤ºæŸ¥è¯¢åˆ†æç»“æœ
    print(f"\nğŸ¯ æŸ¥è¯¢ç‰¹å¾åˆ†æ:")
    query_chars = result['query_characteristics']
    print(f"- æŸ¥è¯¢é•¿åº¦: {query_chars['query_length']} å­—ç¬¦")
    print(f"- è¯æ•°: {query_chars['word_count']}")
    print(f"- å¤æ‚åº¦è¯„åˆ†: {query_chars['complexity_score']}")
    print(f"- æ˜¯å¦å…·ä½“æŸ¥è¯¢: {query_chars['is_specific']}")

    # æ˜¾ç¤ºæ¨èç»“æœ
    print(f"\nğŸ’¡ æ¨èç­–ç•¥:")
    print(f"- æ¨èåˆ†å—å¤§å°: {result['recommended_chunk_size']} å­—ç¬¦")
    print(f"- æ¨èç†ç”±: {result['recommended_reason']}")

    # æ˜¾ç¤ºæ€§èƒ½æ¯”è¾ƒ
    print(f"\nğŸ“ˆ åˆ†å—å¤§å°æ€§èƒ½æ¯”è¾ƒ:")
    print("åˆ†å—å¤§å° | å¹³å‡ç›¸ä¼¼åº¦ | åˆ†å—æ•°é‡ | å¹³å‡åˆ†å—é•¿åº¦")
    print("-" * 50)
    for perf in result['comparison_results'][:5]:
        print(f"{perf['chunk_size']:^8} | {perf['avg_similarity']:^10.4f} | "
              f"{perf['chunk_count']:^8} | {perf['avg_chunk_length']:^12.1f}")

    print(f"\nğŸ† æœ€ä½³åˆ†å—å¤§å°: {result['best_chunk_size']} å­—ç¬¦")

    # æ˜¾ç¤ºæœç´¢ç»“æœ
    print(f"\nğŸ” æœç´¢ç»“æœé¢„è§ˆ:")
    for i, search_result in enumerate(result['best_performance']['search_results'], 1):
        print(f"\nç»“æœ{i} (ç›¸ä¼¼åº¦: {search_result['score']:.4f}):")
        print(f"{search_result['chunk'][:200]}...")

    # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
    print(f"\nğŸ¤– ç”Ÿæˆçš„å›ç­”:")
    print(result['response'])