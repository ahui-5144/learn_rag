import os

from dotenv import load_dotenv
from llama_index.core.base.llms.types import ChatMessage
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.google_genai import GoogleGenAI
from llama_index.llms.openai_like import OpenAILike  # ä¸“ç”¨å…¼å®¹ç±»

load_dotenv()

# æµ‹è¯•åµŒå…¥æ¨¡å‹
print("Testing embedding model....")
embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-base-en-v1.5")
test_embedding = embed_model.get_text_embedding("test")
print(f"âœ… Embedding model working! Vector dimension: {len(test_embedding)}")

# # æµ‹è¯•LLM (å¦‚æœé…ç½®äº†APIå¯†é’¥)
# if os.getenv("GOOGLE_API_KEY"):
#     print("Testing Google Gemini...")
#     llm = GoogleGenAI(model="gemini-2.5-flash")
#     response = llm.complete("Hello, how are you?")
#     print(f"âœ… Google Gemini working! Response: {response}")
# else:
#     print("âš ï¸  Google API key not found, skipping LLM test")
#
# print("ğŸ‰ Environment setup complete!")

api_key=os.getenv("ZHIPU_API_KEY")
zhipu_url=os.getenv("ZHIPU_URL")

if api_key:
    print("Testing ZHIPU GLM ...")
    llm = OpenAILike(
        model="glm-4.7",  # æˆ– "glm-4-plus"ã€"glm-4.7" ç­‰ï¼ˆè§†æ‚¨çš„è´¦å·æ”¯æŒè€Œå®šï¼‰
        api_key=api_key,
        api_base=zhipu_url,
        is_chat_model=True
    )
    # response = llm.complete("Hello, how are you?")
    # æ¨èä½¿ç”¨ chat æ–¹æ³•ï¼ˆç¡®ä¿è°ƒç”¨ /chat/completions ç«¯ç‚¹ï¼Œé¿å… completions 404ï¼‰
    messages = [ChatMessage(role="user", content="Hello, how are you?")]
    response = llm.chat(messages)
    print(f"âœ… ZhiPu working! Response: {response}")
else:
    print("âš ï¸  ZHIPU key not found, skipping LLM test")

print("ğŸ‰ Environment setup complete!")